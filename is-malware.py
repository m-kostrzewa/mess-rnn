#!/usr/bin/python3
#
# Runs a single sample through the whole data collection pipeline, and then
# uses a pretrained model to determine if the sample is malicious or not.
#

from common import *
import analyze
import preprocess
import bundle
import rnn

import numpy as np

log = logging.getLogger("ismalware")
config = configparser.ConfigParser()


def main():
    args = parse_args()
    init(args.config)
    zip_path = collect_data(args)
    encoding_path = preprocess_data(zip_path, args)
    output = predict(encoding_path, args)

    label = "Benevolent" if avg_benevolence > 0.5 else "Malevolent"
    log.info("------ RESULT: %s ------" % (label))


def parse_args():
    parser = argparse.ArgumentParser()
    # parser.add_argument("--input", type=str, required=True,
    #                     help="Path to analyzed sample. Must be relative to "
    #                          "raw_base_dir in config.")
    parser.add_argument("--descriptor", type=str, default=None,
                        help="Path to sample descriptor (if needed). "
                             "Must be relative to raw_base_dir in config.")
    parser.add_argument("--model", type=str, required=True,
                        help="Name of trained model to use. Must be relative "
                             "to best_checkpoint_dir in config.")
    parser.add_argument("--config", type=str, default="mess-rnn.cfg",
                        help="Config filepath.")
    parser.add_argument("--miniseq_len", type=int, default=1000,
                        help="Size of minisequence.")
    return parser.parse_args()


def init(config_path):
    config.read([config_path])
    init_logger(config)


def collect_data(args):
    log.info("------ STEP 1/3: Collecting data (analyze.py) ------")

    in_base_dir = config.get("Workspace", "raw_base_dir")
    sample = [os.path.join(in_base_dir, args.input)]
    descriptor = [os.path.join(in_base_dir, args.descriptor)] \
                 if args.descriptor is not None else []

    analyze.init(args.config)
    zips = analyze.analyze(samples_paths=sample,
                           descriptors_paths=descriptor)
    return zips[0] # we put just one sample in, so we expect only one zip out


def preprocess_data(zip_path, args):
    log.info("------ STEP 2/3: Preprocessing data (preprocess.py) ------")
    target_name = config.get("Common", "sample_target_name")
    preprocess.init(args.config)
    files = preprocess.preprocess([zip_path], target_name,
                                  read_only_opcode_dict=True)
    target_enc_file = [f for f in files if TARGET_FILENAME in f]
    return target_enc_file[0]


def predict(encoding_path, args):
    log.info("------ STEP 3/3: Testing if sample is malicious (rnn.py) ------")
    model_name = args.model

    weights_base_dir = config.get("Workspace", "weights_base_dir")
    hparams_dir = config.get("Workspace", "hyperparams_base_dir")
    tensorboard_dir = config.get("Workspace", "tensorboard_dir")

    sequence, sequence_len = get_longest_sequence(encoding_path)
    embedding_len = bundle.calculate_embedding_len(config)

    vec = allocate_vector(args.miniseq_len, embedding_len)
    
    rnn.init(args.config)
    hyperparams = rnn.load_hyperparams(model_name, hparams_dir)
    data_shape = rnn.get_shape(vec)

    model = rnn.make_model(data_shape, hyperparams, tensorboard_dir, model_name)
    model = rnn.load_weights(model, model_name, weights_base_dir)

    outputs = []
    idx_start = 0
    avg_benevolence = 0.0
    sum_benevolence = 0.0
    batch_idx = 0
    while True:
        vec = populate_vector(vec, sequence, idx_start, args.miniseq_len)
        if vec is None: break
        output = model.predict(vec)
        outputs.append(output)
        idx_start += args.miniseq_len
        batch_idx += 1
        sum_benevolence += output[0][0]
        avg_benevolence = sum_benevolence / batch_idx
        log.debug("Prediction at %s: %s (avg. benevolence: %s)" % 
                  (idx_start+args.miniseq_len, output, avg_benevolence))
    return outputs, avg_benevolence


def get_longest_sequence(encoding_path):
    with open(encoding_path, "r") as f:
        sequences = []
        for line in f:
            seq = sequence_from_line(line)
            sequences.append(seq)
        s = sorted(sequences, key=lambda x: len(x))
        longest = s[-1]
        return longest, len(longest)


def sequence_from_line(line):
    return line.split(",")


def allocate_vector(sequence_len, embedding_len):
    sizeof_f32 = 4
    size = embedding_len * sizeof_f32 / 1024**2
    log.info("Estimated memory required: %i MB" % size)
    vec = np.empty((1, sequence_len, embedding_len),
                   dtype=np.float32)
    return vec


def populate_vector(vec, sequence, idx_start, miniseq_len):
    embedding_len = vec.shape[2]
    
    current_batch = []

    if len(sequence) < idx_start + miniseq_len:
        return None

    subseq = sequence[idx_start:idx_start+miniseq_len]
    for event_idx, event_opcode in enumerate(subseq):
        event_embedding = bundle.embed_event(int(event_opcode),
                                             embedding_len)
        vec[0][event_idx] = event_embedding
    return vec


def prediction_to_string(output_vec):
    predicted_idx = np.asarray(output_vec).astype(float).argmax(1)
    if predicted_idx == 0:
        return "Benevolent"
    else:
        return "Malevolent"


if __name__ == "__main__":
    main()
