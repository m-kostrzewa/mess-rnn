#!/usr/bin/python3
#
# Runs a single sample through the whole data collection pipeline, and then
# uses a pretrained model to determine if the sample is malicious or not.
#

from common import *
import analyze
import preprocess
import bundle
import rnn

import numpy as np

log = logging.getLogger("ismalware")
config = configparser.ConfigParser()


def main():
    args = parse_args()
    init(args.config)
    zip_path = collect_data(args)
    encoding_path = preprocess_data(zip_path, args)
    output = predict(encoding_path, args)
    label = prediction_to_string(output)
    log.info("------ RESULT: %s (raw output: %s) ------" % (label, output))


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", type=str, required=True,
                        help="Path to analyzed sample. Must be relative to "
                             "raw_base_dir in config.")
    parser.add_argument("--descriptor", type=str, default=None,
                        help="Path to sample descriptor (if needed). "
                             "Must be relative to raw_base_dir in config.")
    parser.add_argument("--model", type=str, required=True,
                        help="Name of trained model to use. Must be relative "
                             "to best_checkpoint_dir in config.")
    parser.add_argument("--config", type=str, default="mess-rnn.cfg",
                        help="Config filepath.")
    return parser.parse_args()


def init(config_path):
    config.read([config_path])
    init_logger(config)


def collect_data(args):
    log.info("------ STEP 1/3: Collecting data (analyze.py) ------")

    in_base_dir = config.get("Workspace", "raw_base_dir")
    sample = [os.path.join(in_base_dir, args.input)]
    descriptor = [os.path.join(in_base_dir, args.descriptor)] \
                 if args.descriptor is not None else []

    analyze.init(args.config)
    zips = analyze.analyze(samples_paths=sample,
                           descriptors_paths=descriptor)
    return zips[0] # we put just one sample in, so we expect only one zip out


def preprocess_data(zip_path, args):
    log.info("------ STEP 2/3: Preprocessing data (preprocess.py) ------")
    target_name = config.get("Common", "sample_target_name")
    preprocess.init(args.config)
    files = preprocess.preprocess([zip_path], target_name)
    target_enc_file = [f for f in files if TARGET_FILENAME in f]
    return target_enc_file[0]


def predict(encoding_path, args):
    log.info("------ STEP 3/3: Testing if sample is malicious (rnn.py) ------")
    model_name = args.model

    weights_base_dir = config.get("Workspace", "weights_base_dir")
    hparams_dir = config.get("Workspace", "hyperparams_base_dir")
    tensorboard_dir = config.get("Workspace", "tensorboard_dir")

    vec = convert(encoding_path)
    rnn.init(args.config)
    hyperparams = rnn.load_hyperparams(model_name, hparams_dir)
    data_shape = rnn.get_shape(vec)
    model = rnn.make_model(data_shape, hyperparams, tensorboard_dir, model_name)
    model = rnn.load_weights(model, model_name, weights_base_dir)
    net_output = model.predict(vec)
    return net_output


def convert(encoding_path):
    embedding_len = bundle.calculate_embedding_len(config)
    sequence_len = measure_sequence_lenght(encoding_path)
    vec = allocate_vector(sequence_len, embedding_len)
    vec = populate_vector(vec, encoding_path)
    return vec


def allocate_vector(sequence_len, embedding_len):
    sizeof_f32 = 4
    size = embedding_len * sizeof_f32 / 1024**2
    log.info("Estimated memory required: %i MB" % size)
    vec = np.empty((1, sequence_len, embedding_len),
                   dtype=np.float32)
    log.info("Vec: {}".format(vec.shape))
    return vec


def measure_sequence_lenght(encoding_path):
    with open(encoding_path, "r") as f:
        line = f.readline()
        operations = line.split(",")
    return len(operations)


def populate_vector(vec, encoding_path):
    log.debug("Populating vector")
    embedding_len = vec.shape[2]
    with open(encoding_path, "r") as f:
        line = f.readline()
        operations = line.split(",")
        for event_idx, event_opcode in enumerate(operations):
            event_embedding = bundle.embed_event(int(event_opcode),
                                                 embedding_len)
            vec[0][event_idx] = event_embedding
    log.debug("Vec:\n%s" % vec)
    return vec


def prediction_to_string(output_vec):
    predicted_idx = np.asarray(output_vec).astype(float).argmax(1)
    if predicted_idx == 0:
        return "Benevolent"
    else:
        return "Malevolent"


if __name__ == "__main__":
    main()
